nohup: ignoring input
跳过第一次剪枝 seed=0
[dist initialize] env variable "RANK" is not set, use cuda:0 as the device
[07-30 20:32:51] (IDtest/utils/arg_util.py, line 175)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[07-30 20:32:51] (IDtest/utils/arg_util.py, line 176)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[07-30 20:32:51] (IDtest/utils/arg_util.py, line 177)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[07-30 20:32:51] (/VAR_FIDtest/FID_test.py, line  26)=> /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_0seed_temporary.pth_1epoch/ar-ckpt-best.pth
[07-30 20:32:51] (AR_FIDtest/models/var.py, line  98)=> 
[constructor]  ==== flash_if_available=True (0/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [VAR config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

/home/wangzefang/edgevar/EdgeVAR/slimgpt_pub/slim_utils
[07-30 20:32:51] (AR_FIDtest/models/var.py, line 239)=> [init_weights] VAR with init_std=0.0180422
Namespace(batch_samples=128, cache_dev='cuda', dataset='wikitext2', max_sparsity=0.3, maxlayer=16, min_sparsity=0.06, minlayer=0, model_name='d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth', model_path='/home/sumingluo/Model_weight/meta/llama-2-7b-hf', no_compensate=False, non_uniform=False, non_uniform_strategy='log_increase', num_samples=150, percdamp=0.001, prune_method='slimgpt', save_dir='', save_pruned_weights=False, seed=1, seqlen=2048, skip_evaluate=True, sparsity=0.2, specific_layer=256)
load model...

[constructor]  ==== flash_if_available=True (0/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [VAR config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[init_weights] VAR with init_std=0.0180422
prepare finished.
all params: 0.31 B	 layer params: 0.31 B	 extra params: 0.0 B
load dataset...
start slimming...
[07-30 20:32:54] (/VAR_FIDtest/FID_test.py, line 100)=> 检测到训练检查点文件，正在提取模型权重...
[07-30 20:32:54] (/VAR_FIDtest/FID_test.py, line 106)=> 成功从训练检查点提取模型权重
[07-30 20:32:54] (/VAR_FIDtest/FID_test.py, line 121)=> prepare finished.
生成FID样本:   0%|          | 0/1000 [00:00<?, ?it/s]/home/wangzefang/edgevar/EdgeVAR/VAR_FIDtest/FID_test.py:158: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  label_B: torch.LongTensor = torch.tensor(class_labels, device=device)
生成FID样本:   0%|          | 2/1000 [00:02<16:39,  1.00s/it]生成FID样本:   0%|          | 3/1000 [00:03<23:21,  1.41s/it]生成FID样本:   0%|          | 4/1000 [00:06<27:14,  1.64s/it]生成FID样本:   0%|          | 5/1000 [00:08<29:46,  1.80s/it]生成FID样本:   1%|          | 6/1000 [00:10<31:51,  1.92s/it]生成FID样本:   1%|          | 7/1000 [00:12<31:29,  1.90s/it]生成FID样本:   1%|          | 8/1000 [00:13<30:38,  1.85s/it]生成FID样本:   1%|          | 9/1000 [00:15<29:14,  1.77s/it]生成FID样本:   1%|1         | 10/1000 [00:17<28:11,  1.71s/it]生成FID样本:   1%|1         | 11/1000 [00:18<27:49,  1.69s/it]生成FID样本:   1%|1         | 12/1000 [00:20<28:52,  1.75s/it]生成FID样本:   1%|1         | 13/1000 [00:22<30:07,  1.83s/it]生成FID样本:   1%|1         | 14/1000 [00:24<30:36,  1.86s/it]生成FID样本:   2%|1         | 15/1000 [00:26<30:49,  1.88s/it]生成FID样本:   2%|1         | 16/1000 [00:28<30:51,  1.88s/it]生成FID样本:   2%|1         | 17/1000 [00:30<30:06,  1.84s/it]生成FID样本:   2%|1         | 18/1000 [00:32<30:35,  1.87s/it]生成FID样本:   2%|1         | 19/1000 [00:33<30:15,  1.85s/it]生成FID样本:   2%|2         | 20/1000 [00:35<29:57,  1.83s/it]生成FID样本:   2%|2         | 21/1000 [00:37<30:40,  1.88s/it]生成FID样本:   2%|2         | 22/1000 [00:39<30:19,  1.86s/it]生成FID样本:   2%|2         | 23/1000 [00:41<31:16,  1.92s/it]生成FID样本:   2%|2         | 24/1000 [00:43<31:21,  1.93s/it]生成FID样本:   2%|2         | 25/1000 [00:45<30:54,  1.90s/it]生成FID样本:   3%|2         | 26/1000 [00:46<29:29,  1.82s/it]生成FID样本:   3%|2         | 27/1000 [00:48<28:00,  1.73s/it]生成FID样本:   3%|2         | 28/1000 [00:50<27:51,  1.72s/it]生成FID样本:   3%|2         | 29/1000 [00:51<27:17,  1.69s/it]生成FID样本:   3%|3         | 30/1000 [00:53<27:07,  1.68s/it]生成FID样本:   3%|3         | 31/1000 [00:55<29:02,  1.80s/it]生成FID样本:   3%|3         | 32/1000 [00:57<28:26,  1.76s/it]生成FID样本:   3%|3         | 33/1000 [00:58<28:56,  1.80s/it]生成FID样本:   3%|3         | 34/1000 [01:00<28:21,  1.76s/it]生成FID样本:   4%|3         | 35/1000 [01:02<28:26,  1.77s/it]生成FID样本:   4%|3         | 36/1000 [01:04<28:02,  1.75s/it]生成FID样本:   4%|3         | 37/1000 [01:05<27:24,  1.71s/it]生成FID样本:   4%|3         | 38/1000 [01:07<27:07,  1.69s/it]生成FID样本:   4%|3         | 39/1000 [01:08<26:13,  1.64s/it]生成FID样本:   4%|4         | 40/1000 [01:10<26:52,  1.68s/it]生成FID样本:   4%|4         | 41/1000 [01:12<26:25,  1.65s/it]生成FID样本:   4%|4         | 42/1000 [01:14<27:42,  1.74s/it]生成FID样本:   4%|4         | 43/1000 [01:15<26:49,  1.68s/it]生成FID样本:   4%|4         | 44/1000 [01:17<26:47,  1.68s/it]生成FID样本:   4%|4         | 45/1000 [01:19<26:50,  1.69s/it]生成FID样本:   5%|4         | 46/1000 [01:20<26:20,  1.66s/it]生成FID样本:   5%|4         | 47/1000 [01:22<25:47,  1.62s/it]生成FID样本:   5%|4         | 48/1000 [01:24<26:21,  1.66s/it]生成FID样本:   5%|4         | 49/1000 [01:25<26:30,  1.67s/it]生成FID样本:   5%|5         | 50/1000 [01:27<25:52,  1.63s/it]生成FID样本:   5%|5         | 51/1000 [01:28<25:29,  1.61s/it]生成FID样本:   5%|5         | 52/1000 [01:30<25:04,  1.59s/it]生成FID样本:   5%|5         | 53/1000 [01:32<25:37,  1.62s/it]生成FID样本:   5%|5         | 54/1000 [01:33<25:35,  1.62s/it]生成FID样本:   6%|5         | 55/1000 [01:35<25:39,  1.63s/it]生成FID样本:   6%|5         | 56/1000 [01:36<25:19,  1.61s/it]生成FID样本:   6%|5         | 57/1000 [01:38<26:15,  1.67s/it]生成FID样本:   6%|5         | 58/1000 [01:40<25:44,  1.64s/it]生成FID样本:   6%|5         | 59/1000 [01:41<25:07,  1.60s/it]生成FID样本:   6%|6         | 60/1000 [01:43<25:27,  1.63s/it]生成FID样本:   6%|6         | 61/1000 [01:45<26:54,  1.72s/it]生成FID样本:   6%|6         | 62/1000 [01:47<26:19,  1.68s/it]生成FID样本:   6%|6         | 63/1000 [01:48<26:02,  1.67s/it]生成FID样本:   6%|6         | 64/1000 [01:50<25:44,  1.65s/it]生成FID样本:   6%|6         | 65/1000 [01:51<26:02,  1.67s/it]生成FID样本:   7%|6         | 66/1000 [01:53<27:00,  1.74s/it]生成FID样本:   7%|6         | 67/1000 [01:55<26:34,  1.71s/it]生成FID样本:   7%|6         | 68/1000 [01:57<26:25,  1.70s/it]生成FID样本:   7%|6         | 69/1000 [01:58<25:33,  1.65s/it]生成FID样本:   7%|7         | 70/1000 [02:00<25:25,  1.64s/it]生成FID样本:   7%|7         | 71/1000 [02:01<25:13,  1.63s/it]生成FID样本:   7%|7         | 72/1000 [02:03<26:20,  1.70s/it]生成FID样本:   7%|7         | 73/1000 [02:05<26:11,  1.69s/it]生成FID样本:   7%|7         | 74/1000 [02:07<27:16,  1.77s/it]生成FID样本:   8%|7         | 75/1000 [02:09<27:52,  1.81s/it]生成FID样本:   8%|7         | 76/1000 [02:11<28:25,  1.85s/it]生成FID样本:   8%|7         | 77/1000 [02:13<29:09,  1.90s/it]pruning...
layer 0: attn.proj sparsity 0.2
layer 0: ffn.fc2 sparsity 0.2
生成FID样本:   8%|7         | 78/1000 [02:14<27:42,  1.80s/it]torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 1: attn.proj sparsity 0.2
生成FID样本:   8%|7         | 79/1000 [02:16<27:14,  1.78s/it]layer 1: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 2: attn.proj sparsity 0.2
生成FID样本:   8%|8         | 80/1000 [02:18<28:02,  1.83s/it]layer 2: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:   8%|8         | 81/1000 [02:20<27:13,  1.78s/it]layer 3: attn.proj sparsity 0.2
layer 3: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:   8%|8         | 82/1000 [02:22<27:43,  1.81s/it]layer 4: attn.proj sparsity 0.2
layer 4: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:   8%|8         | 83/1000 [02:23<27:21,  1.79s/it]layer 5: attn.proj sparsity 0.2
生成FID样本:   8%|8         | 84/1000 [02:25<26:26,  1.73s/it]layer 5: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 6: attn.proj sparsity 0.2
生成FID样本:   8%|8         | 85/1000 [02:27<26:35,  1.74s/it]layer 6: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:   9%|8         | 86/1000 [02:28<25:42,  1.69s/it]layer 7: attn.proj sparsity 0.2
layer 7: ffn.fc2 sparsity 0.2
生成FID样本:   9%|8         | 87/1000 [02:30<25:46,  1.69s/it]torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 8: attn.proj sparsity 0.2
生成FID样本:   9%|8         | 88/1000 [02:32<25:37,  1.69s/it]layer 8: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 9: attn.proj sparsity 0.2
生成FID样本:   9%|8         | 89/1000 [02:33<26:14,  1.73s/it]layer 9: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:   9%|9         | 90/1000 [02:35<26:06,  1.72s/it]layer 10: attn.proj sparsity 0.2
layer 10: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:   9%|9         | 91/1000 [02:37<26:57,  1.78s/it]layer 11: attn.proj sparsity 0.2
layer 11: ffn.fc2 sparsity 0.2
生成FID样本:   9%|9         | 92/1000 [02:39<26:31,  1.75s/it]torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 12: attn.proj sparsity 0.2
生成FID样本:   9%|9         | 93/1000 [02:40<26:19,  1.74s/it]layer 12: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
layer 13: attn.proj sparsity 0.2
生成FID样本:   9%|9         | 94/1000 [02:43<27:54,  1.85s/it]layer 13: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:  10%|9         | 95/1000 [02:44<27:42,  1.84s/it]layer 14: attn.proj sparsity 0.2
layer 14: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:  10%|9         | 96/1000 [02:46<28:51,  1.91s/it]layer 15: attn.proj sparsity 0.2
layer 15: ffn.fc2 sparsity 0.2
torch.Size([3277, 1024])
torch.Size([1024, 3277])
torch.Size([3072, 1024])
torch.Size([1024, 1024])
生成FID样本:  10%|9         | 97/1000 [02:49<29:27,  1.96s/it]169.9014332294464
******************************
layer 0 sparsity 0.011433
layer 1 sparsity 0.011433
layer 2 sparsity 0.011433
layer 3 sparsity 0.011433
layer 4 sparsity 0.011433
layer 5 sparsity 0.011433
layer 6 sparsity 0.011433
layer 7 sparsity 0.011433
layer 8 sparsity 0.011433
layer 9 sparsity 0.011433
layer 10 sparsity 0.011433
layer 11 sparsity 0.011433
layer 12 sparsity 0.011433
layer 13 sparsity 0.011433
layer 14 sparsity 0.011433
layer 15 sparsity 0.011433
sparsity sanity check 0.0114
******************************
all params: 0.28 B	 layer params: 0.28 B	 extra params: 0.0 B
decoder_time:56.59937858581543ms
all:{} 0.18358278274536133
VAR(
  drop_path_rate=0.0666667
  (word_embed): Linear(in_features=32, out_features=1024, bias=True)
  (class_emb): Embedding(1001, 1024)
  (lvl_embed): Embedding(10, 1024)
  (shared_ada_lin): Identity()
  (blocks): ModuleList(
    (0): AdaLNSelfAttn(
      shared_aln=False
      (drop_path): Identity()
      (attn): SelfAttention(
        using_flash=False, using_xform=False, attn_l2_norm=True
        (mat_qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): FFN(
        fused_mlp_func=False
        (fc1): Linear(in_features=1024, out_features=3277, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=3277, out_features=1024, bias=True)
        (drop): Identity()
      )
      (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
    (1-15): 15 x AdaLNSelfAttn(
      shared_aln=False
      (drop_path): DropPath((drop_prob=...))
      (attn): SelfAttention(
        using_flash=False, using_xform=False, attn_l2_norm=True
        (mat_qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): FFN(
        fused_mlp_func=False
        (fc1): Linear(in_features=1024, out_features=3277, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=3277, out_features=1024, bias=True)
        (drop): Identity()
      )
      (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
  )
  (head_nm): AdaLNBeforeHead(
    (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
    (ada_lin): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
  )
  (head): Linear(in_features=1024, out_features=4096, bias=True)
)
decoder_time:5.379915237426758ms
decoder_time:5.261421203613281ms
torch.Size([1, 3, 256, 256])
  Params: 283.43 M => 283.43 M
   MACs: 176.76 G => 176.76 G
生成FID样本:  10%|9         | 98/1000 [02:50<28:59,  1.93s/it]生成FID样本:  10%|9         | 99/1000 [02:52<28:47,  1.92s/it]W0730 12:35:47.538723 140315482162240 torch/distributed/run.py:757] 
W0730 12:35:47.538723 140315482162240 torch/distributed/run.py:757] *****************************************
W0730 12:35:47.538723 140315482162240 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0730 12:35:47.538723 140315482162240 torch/distributed/run.py:757] *****************************************
生成FID样本:  10%|#         | 100/1000 [02:54<29:46,  1.98s/it][dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[lrk=5, rk=5]
[lrk=3, rk=3]
[lrk=1, rk=1]
[lrk=0, rk=0]
[lrk=2, rk=2]
[lrk=4, rk=4]
[07-30 20:35:50] (AR/VAR/utils/arg_util.py, line 178)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[07-30 20:35:50] (AR/VAR/utils/arg_util.py, line 179)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[07-30 20:35:50] (AR/VAR/utils/arg_util.py, line 180)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[07-30 20:35:51] (var/EdgeVAR/VAR/train.py, line  41)=> global bs=390, local bs=65
[07-30 20:35:51] (var/EdgeVAR/VAR/train.py, line  42)=> initial args:
{
  data_path           : /home/wangzefang/Datasets/ImageNet-1K
  exp_name            : text
  vfast               : 0
  var_path            : /home/wangzefang/edgevar/EdgeVAR/slimgpt_pub/output/sparsity_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth
  tfast               : 0
  depth               : 16
  sparsity            : 0.2
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 0.00015234375
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  maxlayer            : 16
  bs                  : 390
  batch_size          : 65
  glb_batch_size      : 390
  ac                  : 1
  ep                  : 1
  wp                  : 0.02
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.0033333333333333335
  cmd                 : --depth=16 --bs=390 --ep=1 --fp16=1 --alng=1e-3 --wpe=0.1 --sparsity=0.2 --local_out_dir_path=/home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth_1epoch --data_path=/home/wangzefang/Datasets/ImageNet-1K --var_path=/home/wangzefang/edgevar/EdgeVAR/slimgpt_pub/output/sparsity_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth
  branch              : main
  commit_id           : 8f6a484de1c6ad55bd74076c67b5e9139271b9ff
  commit_msg          : third
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth_1epoch
  tb_log_dir_path     : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth_1epoch/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b390ep1adamlr0.0001wd0.05
  log_txt_path        : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth_1epoch/log.txt
  last_ckpt_path      : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth_1epoch/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  transfer            : False
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[07-30 20:35:51] (var/EdgeVAR/VAR/train.py, line  46)=> [build PT data] ...

生成FID样本:  10%|#         | 101/1000 [02:56<29:14,  1.95s/it]生成FID样本:  10%|#         | 102/1000 [02:58<28:39,  1.91s/it][07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  48)=> Transform [train] = 
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> ToTensor()
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x7f64585c4280>
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  54)=> ---------------------------

[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  48)=> Transform [val] = 
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> ToTensor()
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x7f64585c4280>
[07-30 20:35:53] (dgeVAR/VAR/utils/data.py, line  54)=> ---------------------------

[07-30 20:35:53] (var/EdgeVAR/VAR/train.py, line  69)=> [auto_resume] no ckpt found @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2sparsity_150i_256eva_scale_randomseed_1seed_temporary.pth_1epoch/ar-ckpt*.pth
[07-30 20:35:53] (var/EdgeVAR/VAR/train.py, line  69)=> [auto_resume quit]
[07-30 20:35:53] (var/EdgeVAR/VAR/train.py, line  70)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[07-30 20:35:53] (var/EdgeVAR/VAR/train.py, line  76)=> [dataloader] gbs=390, lbs=65, iters_train=3286, types(tr, va)=('DatasetFolder', 'DatasetFolder')
[07-30 20:35:54] (dgeVAR/VAR/models/var.py, line 102)=> 
[constructor]  ==== flash_if_available=True (0/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [VAR config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[07-30 20:35:54] (dgeVAR/VAR/models/var.py, line 259)=> [init_weights] VAR with init_std=0.0180422
生成FID样本:  10%|#         | 103/1000 [03:00<27:40,  1.85s/it][07-30 20:35:55] (var/EdgeVAR/VAR/train.py, line 108)=> 加载原始模型权重...
[07-30 20:35:55] (var/EdgeVAR/VAR/train.py, line 124)=> [INIT] VAR model = VAR(
  drop_path_rate=0.0666667
  (word_embed): Linear(in_features=32, out_features=1024, bias=True)
  (class_emb): Embedding(1001, 1024)
  (lvl_embed): Embedding(10, 1024)
  (shared_ada_lin): Identity()
  (blocks): ModuleList(
    (0): AdaLNSelfAttn(
      shared_aln=False
      (drop_path): Identity()
      (attn): SelfAttention(
        using_flash=False, using_xform=False, attn_l2_norm=True
        (mat_qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): FFN(
        fused_mlp_func=False
        (fc1): Linear(in_features=1024, out_features=3277, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=3277, out_features=1024, bias=True)
        (drop): Identity()
      )
      (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
    (1-15): 15 x AdaLNSelfAttn(
      shared_aln=False
      (drop_path): DropPath((drop_prob=...))
      (attn): SelfAttention(
        using_flash=False, using_xform=False, attn_l2_norm=True
        (mat_qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): FFN(
        fused_mlp_func=False
        (fc1): Linear(in_features=1024, out_features=3277, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=3277, out_features=1024, bias=True)
        (drop): Identity()
      )
      (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
  )
  (head_nm): AdaLNBeforeHead(
    (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
    (ada_lin): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
  )
  (head): Linear(in_features=1024, out_features=4096, bias=True)
)


[07-30 20:35:55] (var/EdgeVAR/VAR/train.py, line 126)=> [INIT][#para] VAE=108.95, VAE.enc=44.11, VAE.dec=64.65, VAE.quant=0.17
[07-30 20:35:55] (var/EdgeVAR/VAR/train.py, line 127)=> [INIT][#para] VAR=283.43


[07-30 20:35:55] (/VAR/utils/lr_control.py, line  99)=> [get_param_groups] param_groups = 
{ 'D': { 'lr_sc': 1.0,
         'params': "('word_embed.weight, class_emb.weight, blocks.0.attn.mat_qkv.weight, blocks.0.attn.proj.weight, blocks.0.ffn.fc1.weight, blocks.0.ffn.fc2.weight, blocks.0.ada_lin.1.weight, '\n"
                   " 'blocks.1.attn.mat_qkv.weight, blocks.1.attn.proj.weight, blocks.1.ffn.fc1.weight, blocks.1.ffn.fc2.weight, blocks.1.ada_lin.1.weight, blocks.2.attn.mat_qkv.weight, blocks.2.attn.proj.weight, '\n"
                   " 'blocks.2.ffn.fc1.weight, blocks.2.ffn.fc2.weight, blocks.2.ada_lin.1.weight, blocks.3.attn.mat_qkv.weight, blocks.3.attn.proj.weight, blocks.3.ffn.fc1.weight, blocks.3.ffn.fc2.weight, '\n"
                   " 'blocks.3.ada_lin.1.weight, blocks.4.attn.mat_qkv.weight, blocks.4.attn.proj.weight, blocks.4.ffn.fc1.weight, blocks.4.ffn.fc2.weight, blocks.4.ada_lin.1.weight, blocks.5.attn.mat_qkv.weight, '\n"
                   " 'blocks.5.attn.proj.weight, blocks.5.ffn.fc1.weight, blocks.5.ffn.fc2.weight, blocks.5.ada_lin.1.weight, blocks.6.attn.mat_qkv.weight, blocks.6.attn.proj.weight, blocks.6.ffn.fc1.weight, '\n"
                   " 'blocks.6.ffn.fc2.weight, blocks.6.ada_lin.1.weight, blocks.7.attn.mat_qkv.weight, blocks.7.attn.proj.weight, blocks.7.ffn.fc1.weight, blocks.7.ffn.fc2.weight, blocks.7.ada_lin.1.weight, '\n"
                   " 'blocks.8.attn.mat_qkv.weight, blocks.8.attn.proj.weight, blocks.8.ffn.fc1.weight, blocks.8.ffn.fc2.weight, blocks.8.ada_lin.1.weight, blocks.9.attn.mat_qkv.weight, blocks.9.attn.proj.weight, '\n"
                   " 'blocks.9.ffn.fc1.weight, blocks.9.ffn.fc2.weight, blocks.9.ada_lin.1.weight, blocks.10.attn.mat_qkv.weight, blocks.10.attn.proj.weight, blocks.10.ffn.fc1.weight, blocks.10.ffn.fc2.weight, '\n"
                   " 'blocks.10.ada_lin.1.weight, blocks.11.attn.mat_qkv.weight, blocks.11.attn.proj.weight, blocks.11.ffn.fc1.weight, blocks.11.ffn.fc2.weight, blocks.11.ada_lin.1.weight, '\n"
                   " 'blocks.12.attn.mat_qkv.weight, blocks.12.attn.proj.weight, blocks.12.ffn.fc1.weight, blocks.12.ffn.fc2.weight, blocks.12.ada_lin.1.weight, blocks.13.attn.mat_qkv.weight, '\n"
                   " 'blocks.13.attn.proj.weight, blocks.13.ffn.fc1.weight, blocks.13.ffn.fc2.weight, blocks.13.ada_lin.1.weight, blocks.14.attn.mat_qkv.weight, blocks.14.attn.proj.weight, blocks.14.ffn.fc1.weight, '\n"
                   " 'blocks.14.ffn.fc2.weight, blocks.14.ada_lin.1.weight, blocks.15.attn.mat_qkv.weight, blocks.15.attn.proj.weight, blocks.15.ffn.fc1.weight, blocks.15.ffn.fc2.weight, blocks.15.ada_lin.1.weight, '\n"
                   " 'head_nm.ada_lin.1.weight, head.weight')",
         'wd_sc': 1.0},
  'ND': { 'lr_sc': 1.0,
          'params': "('pos_start, pos_1LC, word_embed.bias, lvl_embed.weight, blocks.0.attn.scale_mul_1H11, blocks.0.attn.q_bias, blocks.0.attn.v_bias, blocks.0.attn.proj.bias, blocks.0.ffn.fc1.bias, '\n"
                    " 'blocks.0.ffn.fc2.bias, blocks.0.ada_lin.1.bias, blocks.1.attn.scale_mul_1H11, blocks.1.attn.q_bias, blocks.1.attn.v_bias, blocks.1.attn.proj.bias, blocks.1.ffn.fc1.bias, blocks.1.ffn.fc2.bias, '\n"
                    " 'blocks.1.ada_lin.1.bias, blocks.2.attn.scale_mul_1H11, blocks.2.attn.q_bias, blocks.2.attn.v_bias, blocks.2.attn.proj.bias, blocks.2.ffn.fc1.bias, blocks.2.ffn.fc2.bias, blocks.2.ada_lin.1.bias, '\n"
                    " 'blocks.3.attn.scale_mul_1H11, blocks.3.attn.q_bias, blocks.3.attn.v_bias, blocks.3.attn.proj.bias, blocks.3.ffn.fc1.bias, blocks.3.ffn.fc2.bias, blocks.3.ada_lin.1.bias, '\n"
                    " 'blocks.4.attn.scale_mul_1H11, blocks.4.attn.q_bias, blocks.4.attn.v_bias, blocks.4.attn.proj.bias, blocks.4.ffn.fc1.bias, blocks.4.ffn.fc2.bias, blocks.4.ada_lin.1.bias, '\n"
                    " 'blocks.5.attn.scale_mul_1H11, blocks.5.attn.q_bias, blocks.5.attn.v_bias, blocks.5.attn.proj.bias, blocks.5.ffn.fc1.bias, blocks.5.ffn.fc2.bias, blocks.5.ada_lin.1.bias, '\n"
                    " 'blocks.6.attn.scale_mul_1H11, blocks.6.attn.q_bias, blocks.6.attn.v_bias, blocks.6.attn.proj.bias, blocks.6.ffn.fc1.bias, blocks.6.ffn.fc2.bias, blocks.6.ada_lin.1.bias, '\n"
                    " 'blocks.7.attn.scale_mul_1H11, blocks.7.attn.q_bias, blocks.7.attn.v_bias, blocks.7.attn.proj.bias, blocks.7.ffn.fc1.bias, blocks.7.ffn.fc2.bias, blocks.7.ada_lin.1.bias, '\n"
                    " 'blocks.8.attn.scale_mul_1H11, blocks.8.attn.q_bias, blocks.8.attn.v_bias, blocks.8.attn.proj.bias, blocks.8.ffn.fc1.bias, blocks.8.ffn.fc2.bias, blocks.8.ada_lin.1.bias, '\n"
                    " 'blocks.9.attn.scale_mul_1H11, blocks.9.attn.q_bias, blocks.9.attn.v_bias, blocks.9.attn.proj.bias, blocks.9.ffn.fc1.bias, blocks.9.ffn.fc2.bias, blocks.9.ada_lin.1.bias, '\n"
                    " 'blocks.10.attn.scale_mul_1H11, blocks.10.attn.q_bias, blocks.10.attn.v_bias, blocks.10.attn.proj.bias, blocks.10.ffn.fc1.bias, blocks.10.ffn.fc2.bias, blocks.10.ada_lin.1.bias, '\n"
                    " 'blocks.11.attn.scale_mul_1H11, blocks.11.attn.q_bias, blocks.11.attn.v_bias, blocks.11.attn.proj.bias, blocks.11.ffn.fc1.bias, blocks.11.ffn.fc2.bias, blocks.11.ada_lin.1.bias, '\n"
                    " 'blocks.12.attn.scale_mul_1H11, blocks.12.attn.q_bias, blocks.12.attn.v_bias, blocks.12.attn.proj.bias, blocks.12.ffn.fc1.bias, blocks.12.ffn.fc2.bias, blocks.12.ada_lin.1.bias, '\n"
                    " 'blocks.13.attn.scale_mul_1H11, blocks.13.attn.q_bias, blocks.13.attn.v_bias, blocks.13.attn.proj.bias, blocks.13.ffn.fc1.bias, blocks.13.ffn.fc2.bias, blocks.13.ada_lin.1.bias, '\n"
                    " 'blocks.14.attn.scale_mul_1H11, blocks.14.attn.q_bias, blocks.14.attn.v_bias, blocks.14.attn.proj.bias, blocks.14.ffn.fc1.bias, blocks.14.ffn.fc2.bias, blocks.14.ada_lin.1.bias, '\n"
                    " 'blocks.15.attn.scale_mul_1H11, blocks.15.attn.q_bias, blocks.15.attn.v_bias, blocks.15.attn.proj.bias, blocks.15.ffn.fc1.bias, blocks.15.ffn.fc2.bias, blocks.15.ada_lin.1.bias, '\n"
                    " 'head_nm.ada_lin.1.bias, head.bias')",
          'wd_sc': 0.0}}

生成FID样本:  10%|#         | 104/1000 [03:01<26:12,  1.75s/it][07-30 20:35:56] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank0] type(model).__name__='VAR' count=202, numel=283433424
[07-30 20:35:56] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank1] type(model).__name__='VAR' count=202, numel=283433424
[07-30 20:35:56] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank2] type(model).__name__='VAR' count=202, numel=283433424
[07-30 20:35:56] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank3] type(model).__name__='VAR' count=202, numel=283433424
[07-30 20:35:56] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank4] type(model).__name__='VAR' count=202, numel=283433424
[07-30 20:35:56] (/VAR/utils/lr_control.py, line 105)=> 
[07-30 20:35:56] (var/EdgeVAR/VAR/train.py, line 142)=> [INIT] optim=functools.partial(<class 'torch.optim.adamw.AdamW'>, betas=(0.9, 0.95), fused=True), opt_kw={'lr': 0.00015234375, 'weight_decay': 0}

[07-30 20:35:56] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank5] type(model).__name__='VAR' count=202, numel=283433424
生成FID样本:  10%|#         | 105/1000 [03:03<27:04,  1.81s/it]生成FID样本:  11%|#         | 106/1000 [03:05<25:43,  1.73s/it]生成FID样本:  11%|#         | 107/1000 [03:06<25:01,  1.68s/it]生成FID样本:  11%|#         | 108/1000 [03:08<24:35,  1.65s/it][07-30 20:36:03] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   0/1]  [   0/3286]  eta: 6:11:09  tlr: 7.6e-07  tnm: 5.14  Lm: 7.426 (7.426)  Lt: 6.761 (6.761)  Accm: 1.23 (1.23)  Acct: 2.34 (2.34)  time: 6.7770  data: 0.5361
生成FID样本:  11%|#         | 109/1000 [03:10<26:51,  1.81s/it]生成FID样本:  11%|#1        | 110/1000 [03:12<26:20,  1.78s/it]生成FID样本:  11%|#1        | 111/1000 [03:13<25:22,  1.71s/it]生成FID样本:  11%|#1        | 112/1000 [03:15<24:59,  1.69s/it]生成FID样本:  11%|#1        | 113/1000 [03:17<26:45,  1.81s/it]生成FID样本:  11%|#1        | 114/1000 [03:19<26:41,  1.81s/it]生成FID样本:  12%|#1        | 115/1000 [03:21<26:42,  1.81s/it]生成FID样本:  12%|#1        | 116/1000 [03:22<26:03,  1.77s/it]生成FID样本:  12%|#1        | 117/1000 [03:24<25:43,  1.75s/it]生成FID样本:  12%|#1        | 118/1000 [03:26<25:01,  1.70s/it]生成FID样本:  12%|#1        | 119/1000 [03:28<25:50,  1.76s/it]生成FID样本:  12%|#2        | 120/1000 [03:29<25:35,  1.74s/it]生成FID样本:  12%|#2        | 121/1000 [03:31<24:56,  1.70s/it]生成FID样本:  12%|#2        | 122/1000 [03:33<24:42,  1.69s/it]生成FID样本:  12%|#2        | 123/1000 [03:34<24:45,  1.69s/it]生成FID样本:  12%|#2        | 124/1000 [03:36<25:15,  1.73s/it]生成FID样本:  12%|#2        | 125/1000 [03:38<24:40,  1.69s/it]生成FID样本:  13%|#2        | 126/1000 [03:40<24:53,  1.71s/it]生成FID样本:  13%|#2        | 127/1000 [03:41<25:05,  1.73s/it]生成FID样本:  13%|#2        | 128/1000 [03:43<25:34,  1.76s/it]生成FID样本:  13%|#2        | 129/1000 [03:45<26:11,  1.80s/it]生成FID样本:  13%|#3        | 130/1000 [03:47<26:15,  1.81s/it]生成FID样本:  13%|#3        | 131/1000 [03:49<26:35,  1.84s/it]生成FID样本:  13%|#3        | 132/1000 [03:50<26:10,  1.81s/it]生成FID样本:  13%|#3        | 133/1000 [03:52<25:35,  1.77s/it]生成FID样本:  13%|#3        | 134/1000 [03:54<25:56,  1.80s/it]生成FID样本:  14%|#3        | 135/1000 [03:56<25:14,  1.75s/it]生成FID样本:  14%|#3        | 136/1000 [03:57<25:08,  1.75s/it]生成FID样本:  14%|#3        | 137/1000 [03:59<24:52,  1.73s/it]生成FID样本:  14%|#3        | 138/1000 [04:01<24:25,  1.70s/it]生成FID样本:  14%|#3        | 139/1000 [04:03<25:35,  1.78s/it]生成FID样本:  14%|#4        | 140/1000 [04:04<24:49,  1.73s/it]生成FID样本:  14%|#4        | 141/1000 [04:06<25:45,  1.80s/it]生成FID样本:  14%|#4        | 142/1000 [04:08<26:56,  1.88s/it]生成FID样本:  14%|#4        | 143/1000 [04:10<27:18,  1.91s/it]生成FID样本:  14%|#4        | 144/1000 [04:12<27:37,  1.94s/it]生成FID样本:  14%|#4        | 145/1000 [04:14<27:38,  1.94s/it]生成FID样本:  15%|#4        | 146/1000 [04:16<27:14,  1.91s/it]生成FID样本:  15%|#4        | 147/1000 [04:18<27:03,  1.90s/it]生成FID样本:  15%|#4        | 148/1000 [04:20<27:29,  1.94s/it]生成FID样本:  15%|#4        | 149/1000 [04:22<27:25,  1.93s/it]生成FID样本:  15%|#5        | 150/1000 [04:24<27:07,  1.92s/it]生成FID样本:  15%|#5        | 151/1000 [04:26<28:16,  2.00s/it]生成FID样本:  15%|#5        | 152/1000 [04:28<27:42,  1.96s/it]生成FID样本:  15%|#5        | 153/1000 [04:30<27:15,  1.93s/it]生成FID样本:  15%|#5        | 154/1000 [04:32<27:35,  1.96s/it]生成FID样本:  16%|#5        | 155/1000 [04:34<27:35,  1.96s/it]生成FID样本:  16%|#5        | 156/1000 [04:36<27:00,  1.92s/it]生成FID样本:  16%|#5        | 157/1000 [04:37<26:21,  1.88s/it]生成FID样本:  16%|#5        | 158/1000 [04:39<25:59,  1.85s/it]生成FID样本:  16%|#5        | 159/1000 [04:41<26:21,  1.88s/it]生成FID样本:  16%|#6        | 160/1000 [04:43<26:39,  1.90s/it]生成FID样本:  16%|#6        | 161/1000 [04:45<25:53,  1.85s/it]生成FID样本:  16%|#6        | 162/1000 [04:47<25:30,  1.83s/it]生成FID样本:  16%|#6        | 163/1000 [04:48<25:08,  1.80s/it]生成FID样本:  16%|#6        | 164/1000 [04:50<24:48,  1.78s/it]生成FID样本:  16%|#6        | 165/1000 [04:52<24:41,  1.77s/it]生成FID样本:  17%|#6        | 166/1000 [04:53<24:26,  1.76s/it]生成FID样本:  17%|#6        | 167/1000 [04:55<24:47,  1.79s/it]生成FID样本:  17%|#6        | 168/1000 [04:57<24:55,  1.80s/it]生成FID样本:  17%|#6        | 169/1000 [04:59<25:15,  1.82s/it]生成FID样本:  17%|#7        | 170/1000 [05:01<24:57,  1.80s/it]生成FID样本:  17%|#7        | 171/1000 [05:03<24:50,  1.80s/it]生成FID样本:  17%|#7        | 172/1000 [05:04<23:59,  1.74s/it]生成FID样本:  17%|#7        | 173/1000 [05:06<24:07,  1.75s/it]生成FID样本:  17%|#7        | 174/1000 [05:08<24:00,  1.74s/it]生成FID样本:  18%|#7        | 175/1000 [05:09<23:49,  1.73s/it]生成FID样本:  18%|#7        | 176/1000 [05:11<23:48,  1.73s/it]生成FID样本:  18%|#7        | 177/1000 [05:13<24:01,  1.75s/it]生成FID样本:  18%|#7        | 178/1000 [05:15<23:58,  1.75s/it]生成FID样本:  18%|#7        | 179/1000 [05:16<23:21,  1.71s/it]生成FID样本:  18%|#8        | 180/1000 [05:18<23:15,  1.70s/it]生成FID样本:  18%|#8        | 181/1000 [05:20<23:12,  1.70s/it]生成FID样本:  18%|#8        | 182/1000 [05:21<23:10,  1.70s/it]生成FID样本:  18%|#8        | 183/1000 [05:23<23:40,  1.74s/it]生成FID样本:  18%|#8        | 184/1000 [05:25<23:03,  1.70s/it]生成FID样本:  18%|#8        | 185/1000 [05:27<23:13,  1.71s/it]生成FID样本:  19%|#8        | 186/1000 [05:28<23:05,  1.70s/it]生成FID样本:  19%|#8        | 187/1000 [05:30<22:58,  1.70s/it]生成FID样本:  19%|#8        | 188/1000 [05:32<22:52,  1.69s/it]生成FID样本:  19%|#8        | 189/1000 [05:33<22:57,  1.70s/it]生成FID样本:  19%|#9        | 190/1000 [05:35<23:39,  1.75s/it]生成FID样本:  19%|#9        | 191/1000 [05:37<23:20,  1.73s/it]生成FID样本:  19%|#9        | 192/1000 [05:39<24:35,  1.83s/it]生成FID样本:  19%|#9        | 193/1000 [05:41<23:44,  1.76s/it]生成FID样本:  19%|#9        | 194/1000 [05:42<23:06,  1.72s/it]生成FID样本:  20%|#9        | 195/1000 [05:44<22:54,  1.71s/it]生成FID样本:  20%|#9        | 196/1000 [05:46<23:42,  1.77s/it]生成FID样本:  20%|#9        | 197/1000 [05:48<23:50,  1.78s/it]生成FID样本:  20%|#9        | 198/1000 [05:49<23:28,  1.76s/it]生成FID样本:  20%|#9        | 199/1000 [05:51<23:05,  1.73s/it]生成FID样本:  20%|##        | 200/1000 [05:53<22:59,  1.72s/it]生成FID样本:  20%|##        | 201/1000 [05:54<22:58,  1.73s/it]生成FID样本:  20%|##        | 202/1000 [05:56<23:00,  1.73s/it]生成FID样本:  20%|##        | 203/1000 [05:58<22:21,  1.68s/it]生成FID样本:  20%|##        | 204/1000 [05:59<22:22,  1.69s/it]生成FID样本:  20%|##        | 205/1000 [06:01<22:36,  1.71s/it]生成FID样本:  21%|##        | 206/1000 [06:03<22:48,  1.72s/it]生成FID样本:  21%|##        | 207/1000 [06:05<22:42,  1.72s/it]生成FID样本:  21%|##        | 208/1000 [06:06<22:50,  1.73s/it]生成FID样本:  21%|##        | 209/1000 [06:08<22:54,  1.74s/it]生成FID样本:  21%|##1       | 210/1000 [06:10<22:55,  1.74s/it]生成FID样本:  21%|##1       | 211/1000 [06:12<22:44,  1.73s/it]生成FID样本:  21%|##1       | 212/1000 [06:13<22:30,  1.71s/it]生成FID样本:  21%|##1       | 213/1000 [06:15<22:11,  1.69s/it]生成FID样本:  21%|##1       | 214/1000 [06:17<22:17,  1.70s/it]生成FID样本:  22%|##1       | 215/1000 [06:18<22:06,  1.69s/it]生成FID样本:  22%|##1       | 216/1000 [06:20<22:17,  1.71s/it]生成FID样本:  22%|##1       | 217/1000 [06:22<22:29,  1.72s/it]生成FID样本:  22%|##1       | 218/1000 [06:24<23:05,  1.77s/it]生成FID样本:  22%|##1       | 219/1000 [06:25<22:56,  1.76s/it]生成FID样本:  22%|##2       | 220/1000 [06:27<22:33,  1.73s/it]生成FID样本:  22%|##2       | 221/1000 [06:29<22:26,  1.73s/it]生成FID样本:  22%|##2       | 222/1000 [06:31<22:42,  1.75s/it]生成FID样本:  22%|##2       | 223/1000 [06:32<22:47,  1.76s/it]生成FID样本:  22%|##2       | 224/1000 [06:34<23:12,  1.79s/it]生成FID样本:  22%|##2       | 225/1000 [06:36<23:23,  1.81s/it]生成FID样本:  23%|##2       | 226/1000 [06:38<23:12,  1.80s/it]生成FID样本:  23%|##2       | 227/1000 [06:39<22:34,  1.75s/it]生成FID样本:  23%|##2       | 228/1000 [06:41<22:16,  1.73s/it]生成FID样本:  23%|##2       | 229/1000 [06:43<22:04,  1.72s/it]生成FID样本:  23%|##3       | 230/1000 [06:45<22:02,  1.72s/it]生成FID样本:  23%|##3       | 231/1000 [06:46<22:39,  1.77s/it]生成FID样本:  23%|##3       | 232/1000 [06:48<22:33,  1.76s/it]生成FID样本:  23%|##3       | 233/1000 [06:50<22:26,  1.75s/it]生成FID样本:  23%|##3       | 234/1000 [06:52<22:31,  1.76s/it]生成FID样本:  24%|##3       | 235/1000 [06:53<22:17,  1.75s/it]生成FID样本:  24%|##3       | 236/1000 [06:55<22:02,  1.73s/it]生成FID样本:  24%|##3       | 237/1000 [06:57<21:45,  1.71s/it]生成FID样本:  24%|##3       | 238/1000 [06:59<21:48,  1.72s/it]生成FID样本:  24%|##3       | 239/1000 [07:00<22:00,  1.74s/it]生成FID样本:  24%|##4       | 240/1000 [07:02<22:08,  1.75s/it]生成FID样本:  24%|##4       | 241/1000 [07:04<22:13,  1.76s/it]生成FID样本:  24%|##4       | 242/1000 [07:06<22:05,  1.75s/it]生成FID样本:  24%|##4       | 243/1000 [07:07<22:01,  1.75s/it]生成FID样本:  24%|##4       | 244/1000 [07:09<21:47,  1.73s/it]生成FID样本:  24%|##4       | 245/1000 [07:11<21:51,  1.74s/it]生成FID样本:  25%|##4       | 246/1000 [07:13<22:01,  1.75s/it]生成FID样本:  25%|##4       | 247/1000 [07:14<21:59,  1.75s/it]生成FID样本:  25%|##4       | 248/1000 [07:16<22:03,  1.76s/it]生成FID样本:  25%|##4       | 249/1000 [07:18<22:08,  1.77s/it]生成FID样本:  25%|##5       | 250/1000 [07:20<22:10,  1.77s/it]生成FID样本:  25%|##5       | 251/1000 [07:21<22:01,  1.76s/it]生成FID样本:  25%|##5       | 252/1000 [07:23<22:11,  1.78s/it]生成FID样本:  25%|##5       | 253/1000 [07:25<22:03,  1.77s/it]生成FID样本:  25%|##5       | 254/1000 [07:27<22:23,  1.80s/it]生成FID样本:  26%|##5       | 255/1000 [07:29<22:06,  1.78s/it]生成FID样本:  26%|##5       | 256/1000 [07:30<21:51,  1.76s/it]生成FID样本:  26%|##5       | 257/1000 [07:32<21:27,  1.73s/it]生成FID样本:  26%|##5       | 258/1000 [07:34<21:29,  1.74s/it]生成FID样本:  26%|##5       | 259/1000 [07:36<21:50,  1.77s/it]生成FID样本:  26%|##6       | 260/1000 [07:38<22:34,  1.83s/it]生成FID样本:  26%|##6       | 261/1000 [07:39<22:15,  1.81s/it]生成FID样本:  26%|##6       | 262/1000 [07:41<21:58,  1.79s/it]生成FID样本:  26%|##6       | 263/1000 [07:43<21:38,  1.76s/it]生成FID样本:  26%|##6       | 264/1000 [07:44<21:34,  1.76s/it]生成FID样本:  26%|##6       | 265/1000 [07:46<21:25,  1.75s/it]生成FID样本:  27%|##6       | 266/1000 [07:48<21:27,  1.75s/it]生成FID样本:  27%|##6       | 267/1000 [07:50<21:29,  1.76s/it]生成FID样本:  27%|##6       | 268/1000 [07:51<21:17,  1.75s/it]生成FID样本:  27%|##6       | 269/1000 [07:53<21:04,  1.73s/it]生成FID样本:  27%|##7       | 270/1000 [07:55<21:34,  1.77s/it]生成FID样本:  27%|##7       | 271/1000 [07:57<21:07,  1.74s/it]生成FID样本:  27%|##7       | 272/1000 [07:58<21:16,  1.75s/it]生成FID样本:  27%|##7       | 273/1000 [08:00<20:42,  1.71s/it]生成FID样本:  27%|##7       | 274/1000 [08:02<20:18,  1.68s/it]生成FID样本:  28%|##7       | 275/1000 [08:03<20:09,  1.67s/it]生成FID样本:  28%|##7       | 276/1000 [08:05<20:13,  1.68s/it]生成FID样本:  28%|##7       | 277/1000 [08:07<19:59,  1.66s/it]生成FID样本:  28%|##7       | 278/1000 [08:08<19:31,  1.62s/it]生成FID样本:  28%|##7       | 279/1000 [08:10<19:35,  1.63s/it]生成FID样本:  28%|##8       | 280/1000 [08:11<19:25,  1.62s/it]生成FID样本:  28%|##8       | 281/1000 [08:13<20:21,  1.70s/it]生成FID样本:  28%|##8       | 282/1000 [08:15<20:02,  1.68s/it]生成FID样本:  28%|##8       | 283/1000 [08:17<19:53,  1.66s/it]生成FID样本:  28%|##8       | 284/1000 [08:18<19:38,  1.65s/it]生成FID样本:  28%|##8       | 285/1000 [08:20<20:14,  1.70s/it]生成FID样本:  29%|##8       | 286/1000 [08:22<20:40,  1.74s/it]生成FID样本:  29%|##8       | 287/1000 [08:24<20:37,  1.74s/it]生成FID样本:  29%|##8       | 288/1000 [08:25<20:10,  1.70s/it]生成FID样本:  29%|##8       | 289/1000 [08:27<19:50,  1.67s/it]生成FID样本:  29%|##9       | 290/1000 [08:28<19:21,  1.64s/it]生成FID样本:  29%|##9       | 291/1000 [08:30<19:13,  1.63s/it]生成FID样本:  29%|##9       | 292/1000 [08:31<18:57,  1.61s/it]生成FID样本:  29%|##9       | 293/1000 [08:33<18:46,  1.59s/it]生成FID样本:  29%|##9       | 294/1000 [08:35<18:44,  1.59s/it]生成FID样本:  30%|##9       | 295/1000 [08:36<18:41,  1.59s/it]生成FID样本:  30%|##9       | 296/1000 [08:38<18:49,  1.60s/it]生成FID样本:  30%|##9       | 297/1000 [08:40<18:55,  1.61s/it]生成FID样本:  30%|##9       | 298/1000 [08:41<19:49,  1.69s/it]生成FID样本:  30%|##9       | 299/1000 [08:43<20:03,  1.72s/it]生成FID样本:  30%|###       | 300/1000 [08:45<19:33,  1.68s/it]生成FID样本:  30%|###       | 301/1000 [08:46<19:36,  1.68s/it]生成FID样本:  30%|###       | 302/1000 [08:48<19:32,  1.68s/it]生成FID样本:  30%|###       | 303/1000 [08:50<20:45,  1.79s/it]生成FID样本:  30%|###       | 304/1000 [08:52<20:37,  1.78s/it]生成FID样本:  30%|###       | 305/1000 [08:54<20:59,  1.81s/it]生成FID样本:  31%|###       | 306/1000 [08:56<21:16,  1.84s/it]生成FID样本:  31%|###       | 307/1000 [08:57<20:20,  1.76s/it]生成FID样本:  31%|###       | 308/1000 [08:59<20:28,  1.78s/it]生成FID样本:  31%|###       | 309/1000 [09:01<20:53,  1.81s/it]生成FID样本:  31%|###1      | 310/1000 [09:03<21:17,  1.85s/it]生成FID样本:  31%|###1      | 311/1000 [09:05<21:11,  1.85s/it]生成FID样本:  31%|###1      | 312/1000 [09:07<21:13,  1.85s/it]生成FID样本:  31%|###1      | 313/1000 [09:09<21:23,  1.87s/it]生成FID样本:  31%|###1      | 314/1000 [09:10<21:40,  1.90s/it]生成FID样本:  32%|###1      | 315/1000 [09:12<21:30,  1.88s/it]生成FID样本:  32%|###1      | 316/1000 [09:14<21:18,  1.87s/it]生成FID样本:  32%|###1      | 317/1000 [09:16<21:37,  1.90s/it]生成FID样本:  32%|###1      | 318/1000 [09:18<21:12,  1.87s/it]生成FID样本:  32%|###1      | 319/1000 [09:20<21:10,  1.87s/it]生成FID样本:  32%|###2      | 320/1000 [09:22<21:20,  1.88s/it]生成FID样本:  32%|###2      | 321/1000 [09:24<21:38,  1.91s/it]生成FID样本:  32%|###2      | 322/1000 [09:26<22:02,  1.95s/it]生成FID样本:  32%|###2      | 323/1000 [09:28<21:37,  1.92s/it]