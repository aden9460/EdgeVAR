nohup: ignoring input
W0728 12:47:26.993877 140240809432128 torch/distributed/run.py:757] 
W0728 12:47:26.993877 140240809432128 torch/distributed/run.py:757] *****************************************
W0728 12:47:26.993877 140240809432128 torch/distributed/run.py:757] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0728 12:47:26.993877 140240809432128 torch/distributed/run.py:757] *****************************************
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[dist initialize] mp method=spawn
[lrk=1, rk=1]
[lrk=6, rk=6]
[lrk=4, rk=4]
[lrk=2, rk=2]
[lrk=3, rk=3]
[lrk=5, rk=5]
[lrk=0, rk=0]
[07-28 20:47:30] (AR/VAR/utils/arg_util.py, line 176)=> [tf32] [precis] torch.get_float32_matmul_precision(): high
[07-28 20:47:30] (AR/VAR/utils/arg_util.py, line 177)=> [tf32] [ conv ] torch.backends.cudnn.allow_tf32: True
[07-28 20:47:30] (AR/VAR/utils/arg_util.py, line 178)=> [tf32] [matmul] torch.backends.cuda.matmul.allow_tf32: True
[07-28 20:47:30] (train.py                , line  41)=> global bs=469, local bs=67
[07-28 20:47:30] (train.py                , line  42)=> initial args:
{
  data_path           : /home/wangzefang/Datasets/ImageNet-1K
  exp_name            : text
  vfast               : 0
  tfast               : 0
  depth               : 16
  sparsity            : 0.2
  ini                 : -1
  hd                  : 0.02
  aln                 : 0.5
  alng                : 0.001
  fp16                : 1
  tblr                : 0.0001
  tlr                 : 0.00018320312500000002
  twd                 : 0.05
  twde                : 0.05
  tclip               : 2.0
  ls                  : 0.0
  bs                  : 469
  batch_size          : 67
  glb_batch_size      : 469
  ac                  : 1
  ep                  : 20
  wp                  : 0.4
  wp0                 : 0.005
  wpe                 : 0.1
  sche                : lin0
  opt                 : adamw
  afuse               : True
  saln                : False
  anorm               : True
  fuse                : True
  pn                  : 1_2_3_4_5_6_8_10_13_16
  patch_size          : 16
  patch_nums          : (1, 2, 3, 4, 5, 6, 8, 10, 13, 16)
  resos               : (16, 32, 48, 64, 80, 96, 128, 160, 208, 256)
  data_load_reso      : 256
  mid_reso            : 1.125
  hflip               : False
  workers             : 0
  pg                  : 0.0
  pg0                 : 4
  pgwp                : 0.06666666666666667
  cmd                 : --depth=16 --bs=470 --ep=20 --fp16=1 --alng=1e-3 --wpe=0.1 --sparsity=0.2 --local_out_dir_path=/home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i --data_path=/home/wangzefang/Datasets/ImageNet-1K
  branch              : main
  commit_id           : 7f20a79b1faa2534c4cd8a4dea3fbb72fb0375d0
  commit_msg          : Add external libraries as normal code
  acc_mean            : None
  acc_tail            : None
  L_mean              : None
  L_tail              : None
  vacc_mean           : None
  vacc_tail           : None
  vL_mean             : None
  vL_tail             : None
  grad_norm           : None
  cur_lr              : None
  cur_wd              : None
  cur_it              : 
  cur_ep              : 
  remain_time         : 
  finish_time         : 
  local_out_dir_path  : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i
  tb_log_dir_path     : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/tb-VARd16__pn1_2_3_4_5_6_8_10_13_16__b469ep20adamlr0.0001wd0.05
  log_txt_path        : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/log.txt
  last_ckpt_path      : /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
  tf32                : True
  seed                : None
  transfer            : False
  same_seed_for_all_ranks: 0
  local_debug         : False
  dbg_nan             : False
}

[07-28 20:47:30] (train.py                , line  46)=> [build PT data] ...

[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  34)=> [Dataset] len(train_set)=1281167, len(val_set)=50000, num_classes=1000
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  48)=> Transform [train] = 
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> RandomCrop(size=(256, 256), padding=None)
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> ToTensor()
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x7f69505d41f0>
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  54)=> ---------------------------

[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  48)=> Transform [val] = 
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> Resize(size=288, interpolation=lanczos, max_size=None, antialias=True)
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> CenterCrop(size=(256, 256))
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> ToTensor()
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  51)=> <function normalize_01_into_pm1 at 0x7f69505d41f0>
[07-28 20:47:33] (dgeVAR/VAR/utils/data.py, line  54)=> ---------------------------

[07-28 20:47:33] (train.py                , line  69)=> [auto_resume] no ckpt found @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt*.pth
[07-28 20:47:33] (train.py                , line  69)=> [auto_resume quit]
[07-28 20:47:33] (train.py                , line  70)=> [dataloader multi processing] ...     [dataloader multi processing](*) finished! (0.00s)
[07-28 20:47:33] (train.py                , line  76)=> [dataloader] gbs=469, lbs=67, iters_train=2732, types(tr, va)=('DatasetFolder', 'DatasetFolder')
[07-28 20:47:33] (dgeVAR/VAR/models/var.py, line 102)=> 
[constructor]  ==== flash_if_available=True (0/16), fused_if_available=True (fusing_add_ln=0/16, fusing_mlp=0/16) ==== 
    [VAR config ] embed_dim=1024, num_heads=16, depth=16, mlp_ratio=4.0
    [drop ratios ] drop_rate=0.0, attn_drop_rate=0.0, drop_path_rate=0.0666667 (tensor([0.0000, 0.0044, 0.0089, 0.0133, 0.0178, 0.0222, 0.0267, 0.0311, 0.0356,
        0.0400, 0.0444, 0.0489, 0.0533, 0.0578, 0.0622, 0.0667]))

[07-28 20:47:33] (dgeVAR/VAR/models/var.py, line 259)=> [init_weights] VAR with init_std=0.0180422
[07-28 20:47:34] (train.py                , line 108)=> 加载原始模型权重...
[07-28 20:47:34] (train.py                , line 124)=> [INIT] VAR model = VAR(
  drop_path_rate=0.0666667
  (word_embed): Linear(in_features=32, out_features=1024, bias=True)
  (class_emb): Embedding(1001, 1024)
  (lvl_embed): Embedding(10, 1024)
  (shared_ada_lin): Identity()
  (blocks): ModuleList(
    (0): AdaLNSelfAttn(
      shared_aln=False
      (drop_path): Identity()
      (attn): SelfAttention(
        using_flash=False, using_xform=False, attn_l2_norm=True
        (mat_qkv): Linear(in_features=1024, out_features=2496, bias=False)
        (proj): Linear(in_features=832, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): FFN(
        fused_mlp_func=False
        (fc1): Linear(in_features=1024, out_features=3277, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=3277, out_features=1024, bias=True)
        (drop): Identity()
      )
      (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
    (1-15): 15 x AdaLNSelfAttn(
      shared_aln=False
      (drop_path): DropPath((drop_prob=...))
      (attn): SelfAttention(
        using_flash=False, using_xform=False, attn_l2_norm=True
        (mat_qkv): Linear(in_features=1024, out_features=2496, bias=False)
        (proj): Linear(in_features=832, out_features=1024, bias=True)
        (proj_drop): Identity()
      )
      (ffn): FFN(
        fused_mlp_func=False
        (fc1): Linear(in_features=1024, out_features=3277, bias=True)
        (act): GELU(approximate='tanh')
        (fc2): Linear(in_features=3277, out_features=1024, bias=True)
        (drop): Identity()
      )
      (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
      (ada_lin): Sequential(
        (0): SiLU()
        (1): Linear(in_features=1024, out_features=6144, bias=True)
      )
    )
  )
  (head_nm): AdaLNBeforeHead(
    (ln_wo_grad): LayerNorm((1024,), eps=1e-06, elementwise_affine=False)
    (ada_lin): Sequential(
      (0): SiLU()
      (1): Linear(in_features=1024, out_features=2048, bias=True)
    )
  )
  (head): Linear(in_features=1024, out_features=4096, bias=True)
)


[07-28 20:47:34] (train.py                , line 126)=> [INIT][#para] VAE=108.95, VAE.enc=44.11, VAE.dec=64.65, VAE.quant=0.17
[07-28 20:47:34] (train.py                , line 127)=> [INIT][#para] VAR=270.84


[07-28 20:47:34] (/VAR/utils/lr_control.py, line  99)=> [get_param_groups] param_groups = 
{ 'D': { 'lr_sc': 1.0,
         'params': "('word_embed.weight, class_emb.weight, blocks.0.attn.mat_qkv.weight, blocks.0.attn.proj.weight, blocks.0.ffn.fc1.weight, blocks.0.ffn.fc2.weight, blocks.0.ada_lin.1.weight, '\n"
                   " 'blocks.1.attn.mat_qkv.weight, blocks.1.attn.proj.weight, blocks.1.ffn.fc1.weight, blocks.1.ffn.fc2.weight, blocks.1.ada_lin.1.weight, blocks.2.attn.mat_qkv.weight, blocks.2.attn.proj.weight, '\n"
                   " 'blocks.2.ffn.fc1.weight, blocks.2.ffn.fc2.weight, blocks.2.ada_lin.1.weight, blocks.3.attn.mat_qkv.weight, blocks.3.attn.proj.weight, blocks.3.ffn.fc1.weight, blocks.3.ffn.fc2.weight, '\n"
                   " 'blocks.3.ada_lin.1.weight, blocks.4.attn.mat_qkv.weight, blocks.4.attn.proj.weight, blocks.4.ffn.fc1.weight, blocks.4.ffn.fc2.weight, blocks.4.ada_lin.1.weight, blocks.5.attn.mat_qkv.weight, '\n"
                   " 'blocks.5.attn.proj.weight, blocks.5.ffn.fc1.weight, blocks.5.ffn.fc2.weight, blocks.5.ada_lin.1.weight, blocks.6.attn.mat_qkv.weight, blocks.6.attn.proj.weight, blocks.6.ffn.fc1.weight, '\n"
                   " 'blocks.6.ffn.fc2.weight, blocks.6.ada_lin.1.weight, blocks.7.attn.mat_qkv.weight, blocks.7.attn.proj.weight, blocks.7.ffn.fc1.weight, blocks.7.ffn.fc2.weight, blocks.7.ada_lin.1.weight, '\n"
                   " 'blocks.8.attn.mat_qkv.weight, blocks.8.attn.proj.weight, blocks.8.ffn.fc1.weight, blocks.8.ffn.fc2.weight, blocks.8.ada_lin.1.weight, blocks.9.attn.mat_qkv.weight, blocks.9.attn.proj.weight, '\n"
                   " 'blocks.9.ffn.fc1.weight, blocks.9.ffn.fc2.weight, blocks.9.ada_lin.1.weight, blocks.10.attn.mat_qkv.weight, blocks.10.attn.proj.weight, blocks.10.ffn.fc1.weight, blocks.10.ffn.fc2.weight, '\n"
                   " 'blocks.10.ada_lin.1.weight, blocks.11.attn.mat_qkv.weight, blocks.11.attn.proj.weight, blocks.11.ffn.fc1.weight, blocks.11.ffn.fc2.weight, blocks.11.ada_lin.1.weight, '\n"
                   " 'blocks.12.attn.mat_qkv.weight, blocks.12.attn.proj.weight, blocks.12.ffn.fc1.weight, blocks.12.ffn.fc2.weight, blocks.12.ada_lin.1.weight, blocks.13.attn.mat_qkv.weight, '\n"
                   " 'blocks.13.attn.proj.weight, blocks.13.ffn.fc1.weight, blocks.13.ffn.fc2.weight, blocks.13.ada_lin.1.weight, blocks.14.attn.mat_qkv.weight, blocks.14.attn.proj.weight, blocks.14.ffn.fc1.weight, '\n"
                   " 'blocks.14.ffn.fc2.weight, blocks.14.ada_lin.1.weight, blocks.15.attn.mat_qkv.weight, blocks.15.attn.proj.weight, blocks.15.ffn.fc1.weight, blocks.15.ffn.fc2.weight, blocks.15.ada_lin.1.weight, '\n"
                   " 'head_nm.ada_lin.1.weight, head.weight')",
         'wd_sc': 1.0},
  'ND': { 'lr_sc': 1.0,
          'params': "('pos_start, pos_1LC, word_embed.bias, lvl_embed.weight, blocks.0.attn.scale_mul_1H11, blocks.0.attn.q_bias, blocks.0.attn.v_bias, blocks.0.attn.proj.bias, blocks.0.ffn.fc1.bias, '\n"
                    " 'blocks.0.ffn.fc2.bias, blocks.0.ada_lin.1.bias, blocks.1.attn.scale_mul_1H11, blocks.1.attn.q_bias, blocks.1.attn.v_bias, blocks.1.attn.proj.bias, blocks.1.ffn.fc1.bias, blocks.1.ffn.fc2.bias, '\n"
                    " 'blocks.1.ada_lin.1.bias, blocks.2.attn.scale_mul_1H11, blocks.2.attn.q_bias, blocks.2.attn.v_bias, blocks.2.attn.proj.bias, blocks.2.ffn.fc1.bias, blocks.2.ffn.fc2.bias, blocks.2.ada_lin.1.bias, '\n"
                    " 'blocks.3.attn.scale_mul_1H11, blocks.3.attn.q_bias, blocks.3.attn.v_bias, blocks.3.attn.proj.bias, blocks.3.ffn.fc1.bias, blocks.3.ffn.fc2.bias, blocks.3.ada_lin.1.bias, '\n"
                    " 'blocks.4.attn.scale_mul_1H11, blocks.4.attn.q_bias, blocks.4.attn.v_bias, blocks.4.attn.proj.bias, blocks.4.ffn.fc1.bias, blocks.4.ffn.fc2.bias, blocks.4.ada_lin.1.bias, '\n"
                    " 'blocks.5.attn.scale_mul_1H11, blocks.5.attn.q_bias, blocks.5.attn.v_bias, blocks.5.attn.proj.bias, blocks.5.ffn.fc1.bias, blocks.5.ffn.fc2.bias, blocks.5.ada_lin.1.bias, '\n"
                    " 'blocks.6.attn.scale_mul_1H11, blocks.6.attn.q_bias, blocks.6.attn.v_bias, blocks.6.attn.proj.bias, blocks.6.ffn.fc1.bias, blocks.6.ffn.fc2.bias, blocks.6.ada_lin.1.bias, '\n"
                    " 'blocks.7.attn.scale_mul_1H11, blocks.7.attn.q_bias, blocks.7.attn.v_bias, blocks.7.attn.proj.bias, blocks.7.ffn.fc1.bias, blocks.7.ffn.fc2.bias, blocks.7.ada_lin.1.bias, '\n"
                    " 'blocks.8.attn.scale_mul_1H11, blocks.8.attn.q_bias, blocks.8.attn.v_bias, blocks.8.attn.proj.bias, blocks.8.ffn.fc1.bias, blocks.8.ffn.fc2.bias, blocks.8.ada_lin.1.bias, '\n"
                    " 'blocks.9.attn.scale_mul_1H11, blocks.9.attn.q_bias, blocks.9.attn.v_bias, blocks.9.attn.proj.bias, blocks.9.ffn.fc1.bias, blocks.9.ffn.fc2.bias, blocks.9.ada_lin.1.bias, '\n"
                    " 'blocks.10.attn.scale_mul_1H11, blocks.10.attn.q_bias, blocks.10.attn.v_bias, blocks.10.attn.proj.bias, blocks.10.ffn.fc1.bias, blocks.10.ffn.fc2.bias, blocks.10.ada_lin.1.bias, '\n"
                    " 'blocks.11.attn.scale_mul_1H11, blocks.11.attn.q_bias, blocks.11.attn.v_bias, blocks.11.attn.proj.bias, blocks.11.ffn.fc1.bias, blocks.11.ffn.fc2.bias, blocks.11.ada_lin.1.bias, '\n"
                    " 'blocks.12.attn.scale_mul_1H11, blocks.12.attn.q_bias, blocks.12.attn.v_bias, blocks.12.attn.proj.bias, blocks.12.ffn.fc1.bias, blocks.12.ffn.fc2.bias, blocks.12.ada_lin.1.bias, '\n"
                    " 'blocks.13.attn.scale_mul_1H11, blocks.13.attn.q_bias, blocks.13.attn.v_bias, blocks.13.attn.proj.bias, blocks.13.ffn.fc1.bias, blocks.13.ffn.fc2.bias, blocks.13.ada_lin.1.bias, '\n"
                    " 'blocks.14.attn.scale_mul_1H11, blocks.14.attn.q_bias, blocks.14.attn.v_bias, blocks.14.attn.proj.bias, blocks.14.ffn.fc1.bias, blocks.14.ffn.fc2.bias, blocks.14.ada_lin.1.bias, '\n"
                    " 'blocks.15.attn.scale_mul_1H11, blocks.15.attn.q_bias, blocks.15.attn.v_bias, blocks.15.attn.proj.bias, blocks.15.ffn.fc1.bias, blocks.15.ffn.fc2.bias, blocks.15.ada_lin.1.bias, '\n"
                    " 'head_nm.ada_lin.1.bias, head.bias')",
          'wd_sc': 0.0}}

[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank0] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank1] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank2] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank3] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank4] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank5] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:36] (/VAR/utils/lr_control.py, line 105)=> 
[07-28 20:47:36] (train.py                , line 142)=> [INIT] optim=functools.partial(<class 'torch.optim.adamw.AdamW'>, betas=(0.9, 0.95), fused=True), opt_kw={'lr': 0.00018320312500000002, 'weight_decay': 0}

[07-28 20:47:36] (/VAR/utils/lr_control.py, line 104)=> [get_param_groups][rank6] type(model).__name__='VAR' count=202, numel=270844320
[07-28 20:47:43] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   0/20]  [   0/2732]  eta: 5:18:38  tlr: 9.2e-07  tnm: 73.32  Lm: 16.737 (16.737)  Lt: 15.368 (15.368)  Accm: 0.03 (0.03)  Acct: 0.03 (0.03)  time: 6.9980  data: 0.5484
[07-28 21:30:02] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   0/20]  [ 682/2732]  eta: 2:07:22  tlr: 0.00011  tnm: 0.71  Lm: 12.188 (12.188)  Lt: 11.530 (11.530)  Accm: 0.35 (0.35)  Acct: 0.22 (0.22)  time: 3.6615  data: 0.5575
[07-28 22:15:38] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   0/20]  [1365/2732]  eta: 1:28:05  tlr: 0.00018  tnm: 0.47  Lm: 7.640 (10.497)  Lt: 7.691 (10.064)  Accm: 0.68 (0.83)  Acct: 0.42 (0.62)  time: 3.7048  data: 0.5556
[07-28 22:57:40] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   0/20]  [2048/2732]  eta: 0:43:25  tlr: 0.00018  tnm: 0.49  Lm: 7.377 (9.599)  Lt: 7.412 (9.213)  Accm: 1.23 (1.16)  Acct: 0.91 (1.06)  time: 3.6986  data: 0.5654
[07-28 23:39:40] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   0/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00018  tnm: 0.42  Lm: 7.115 (9.017)  Lt: 7.134 (8.621)  Accm: 1.78 (1.48)  Acct: 1.41 (1.58)  time: 3.6433  data: 0.5554
[07-28 23:39:40] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   0/20]   Total time:      2:52:03   (3.779 s / it)
[07-28 23:41:33] (train.py                , line 236)=>  [*] [ep0]  (val 50000)  Lm: 9.0207, Lt: 8.6150, Acc m&t: 1.38 1.56,  Val cost: 113.37s
[07-28 23:41:33] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-28 23:41:42] (train.py                , line 253)=>      [ep0]  (training )  Lm: 9.021 (9.021), Lt: 8.615 (8.615),  Acc m&t: 1.38 1.56,  Remain: 2 days, 5:06:05,  Finish: 2025-07-30 20:45
[07-28 23:41:45] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   1/20]  [   0/2732]  eta: 2:43:28  tlr: 0.00018  tnm: 0.44  Lm: 6.683 (6.683)  Lt: 6.231 (6.231)  Accm: 2.72 (2.72)  Acct: 3.78 (3.78)  time: 3.5903  data: 0.5420
[07-29 00:23:26] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   1/20]  [ 682/2732]  eta: 2:05:16  tlr: 0.00018  tnm: 0.40  Lm: 6.666 (6.666)  Lt: 6.164 (6.164)  Accm: 2.80 (2.80)  Acct: 4.09 (4.09)  time: 3.7130  data: 0.5392
[07-29 01:05:33] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   1/20]  [1365/2732]  eta: 1:23:54  tlr: 0.00018  tnm: 0.36  Lm: 6.649 (6.636)  Lt: 6.097 (6.110)  Accm: 2.82 (2.81)  Acct: 4.29 (4.16)  time: 3.6833  data: 0.5420
[07-29 01:47:32] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   1/20]  [2048/2732]  eta: 0:42:00  tlr: 0.00018  tnm: 0.35  Lm: 6.612 (6.587)  Lt: 6.049 (6.050)  Accm: 2.86 (2.98)  Acct: 4.34 (4.38)  time: 3.6702  data: 0.5504
[07-29 02:29:36] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   1/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00018  tnm: 0.37  Lm: 6.575 (6.562)  Lt: 6.002 (6.015)  Accm: 2.89 (3.02)  Acct: 4.39 (4.52)  time: 3.7113  data: 0.5584
[07-29 02:29:36] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   1/20]   Total time:      2:47:53   (3.687 s / it)
[07-29 02:31:21] (train.py                , line 236)=>  [*] [ep1]  (val 50000)  Lm: 6.5311, Lt: 5.9953, Acc m&t: 3.22 4.67,  Val cost: 105.03s
[07-29 02:31:21] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 02:31:40] (train.py                , line 253)=>      [ep1]  (training )  Lm: 6.531 (6.531), Lt: 5.995 (5.995),  Acc m&t: 3.22 4.67,  Remain: 2 days, 2:46:01,  Finish: 2025-07-30 21:15
[07-29 02:31:44] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   2/20]  [   0/2732]  eta: 2:55:35  tlr: 0.00018  tnm: 0.38  Lm: 6.426 (6.426)  Lt: 5.789 (5.789)  Accm: 3.87 (3.87)  Acct: 5.96 (5.96)  time: 3.8562  data: 0.5531
[07-29 03:13:45] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   2/20]  [ 682/2732]  eta: 2:06:17  tlr: 0.00018  tnm: 0.34  Lm: 6.459 (6.459)  Lt: 5.826 (5.826)  Accm: 3.56 (3.56)  Acct: 5.42 (5.42)  time: 3.6939  data: 0.5567
[07-29 03:55:47] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   2/20]  [1365/2732]  eta: 1:24:10  tlr: 0.00017  tnm: 0.33  Lm: 6.426 (6.405)  Lt: 5.789 (5.781)  Accm: 3.87 (3.76)  Acct: 5.96 (5.64)  time: 3.6946  data: 0.5761
[07-29 04:37:48] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   2/20]  [2048/2732]  eta: 0:42:06  tlr: 0.00017  tnm: 0.33  Lm: 6.361 (6.373)  Lt: 5.761 (5.768)  Accm: 4.02 (3.96)  Acct: 6.02 (5.75)  time: 3.6795  data: 0.5427
[07-29 05:19:51] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   2/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00017  tnm: 0.34  Lm: 6.332 (6.365)  Lt: 5.732 (5.758)  Accm: 3.94 (3.96)  Acct: 5.96 (5.75)  time: 3.7181  data: 0.5449
[07-29 05:19:51] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   2/20]   Total time:      2:48:11   (3.694 s / it)
[07-29 05:21:35] (train.py                , line 236)=>  [*] [ep2]  (val 50000)  Lm: 6.3932, Lt: 5.7750, Acc m&t: 3.74 5.59,  Val cost: 103.98s
[07-29 05:21:35] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 05:21:55] (train.py                , line 253)=>      [ep2]  (training )  Lm: 6.393 (6.393), Lt: 5.775 (5.775),  Acc m&t: 3.74 5.59,  Remain: 1 day, 23:55:00,  Finish: 2025-07-30 21:14
[07-29 05:21:59] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   3/20]  [   0/2732]  eta: 2:55:39  tlr: 0.00017  tnm: 0.32  Lm: 6.360 (6.360)  Lt: 5.723 (5.723)  Accm: 3.73 (3.73)  Acct: 6.02 (6.02)  time: 3.8578  data: 0.5742
[07-29 06:04:00] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   3/20]  [ 682/2732]  eta: 2:06:18  tlr: 0.00017  tnm: 0.32  Lm: 6.292 (6.292)  Lt: 5.671 (5.671)  Accm: 4.21 (4.21)  Acct: 6.35 (6.35)  time: 3.7073  data: 0.5415
[07-29 06:46:00] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   3/20]  [1365/2732]  eta: 1:24:09  tlr: 0.00016  tnm: 0.33  Lm: 6.360 (6.319)  Lt: 5.675 (5.672)  Accm: 3.79 (4.07)  Acct: 6.11 (6.27)  time: 3.7039  data: 0.5496
[07-29 07:28:01] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   3/20]  [2048/2732]  eta: 0:42:05  tlr: 0.00016  tnm: 0.32  Lm: 6.356 (6.327)  Lt: 5.673 (5.672)  Accm: 3.87 (4.04)  Acct: 6.13 (6.24)  time: 3.7171  data: 0.5658
[07-29 08:10:04] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   3/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00016  tnm: 0.33  Lm: 6.360 (6.337)  Lt: 5.675 (5.676)  Accm: 3.79 (3.95)  Acct: 6.11 (6.19)  time: 3.7065  data: 0.5571
[07-29 08:10:04] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   3/20]   Total time:      2:48:08   (3.693 s / it)
[07-29 08:11:48] (train.py                , line 236)=>  [*] [ep3]  (val 50000)  Lm: 6.3354, Lt: 5.6969, Acc m&t: 3.92 5.95,  Val cost: 104.03s
[07-29 08:11:48] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 08:12:07] (train.py                , line 253)=>      [ep3]  (training )  Lm: 6.335 (6.335), Lt: 5.697 (5.697),  Acc m&t: 3.92 5.95,  Remain: 1 day, 21:12:49,  Finish: 2025-07-30 21:22
[07-29 08:12:11] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   4/20]  [   0/2732]  eta: 2:50:01  tlr: 0.00016  tnm: 0.32  Lm: 6.321 (6.321)  Lt: 5.665 (5.665)  Accm: 4.02 (4.02)  Acct: 6.38 (6.38)  time: 3.7342  data: 0.6955
[07-29 08:54:11] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   4/20]  [ 682/2732]  eta: 2:06:14  tlr: 0.00016  tnm: 0.33  Lm: 6.290 (6.290)  Lt: 5.645 (5.645)  Accm: 4.16 (4.16)  Acct: 6.31 (6.31)  time: 3.6989  data: 0.5595
[07-29 09:36:11] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   4/20]  [1365/2732]  eta: 1:24:07  tlr: 0.00016  tnm: 0.30  Lm: 6.260 (6.253)  Lt: 5.624 (5.617)  Accm: 4.30 (4.34)  Acct: 6.38 (6.43)  time: 3.6661  data: 0.5296
[07-29 10:18:12] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   4/20]  [2048/2732]  eta: 0:42:05  tlr: 0.00015  tnm: 0.32  Lm: 6.274 (6.262)  Lt: 5.622 (5.618)  Accm: 4.16 (4.23)  Acct: 6.31 (6.31)  time: 3.7040  data: 0.5474
[07-29 11:00:15] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   4/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00015  tnm: 0.31  Lm: 6.289 (6.281)  Lt: 5.624 (5.632)  Accm: 4.02 (4.16)  Acct: 6.24 (6.24)  time: 3.6904  data: 0.5417
[07-29 11:00:15] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   4/20]   Total time:      2:48:07   (3.692 s / it)
[07-29 11:01:58] (train.py                , line 236)=>  [*] [ep4]  (val 50000)  Lm: 6.2811, Lt: 5.6419, Acc m&t: 4.16 6.23,  Val cost: 103.96s
[07-29 11:01:58] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 11:02:18] (train.py                , line 253)=>      [ep4]  (training )  Lm: 6.281 (6.281), Lt: 5.642 (5.642),  Acc m&t: 4.16 6.23,  Remain: 1 day, 18:06:51,  Finish: 2025-07-30 21:07
[07-29 11:02:22] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   5/20]  [   0/2732]  eta: 2:53:02  tlr: 0.00015  tnm: 0.32  Lm: 6.307 (6.307)  Lt: 5.648 (5.648)  Accm: 4.01 (4.01)  Acct: 6.30 (6.30)  time: 3.8004  data: 0.7615
[07-29 11:44:22] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   5/20]  [ 682/2732]  eta: 2:06:14  tlr: 0.00015  tnm: 0.32  Lm: 6.326 (6.326)  Lt: 5.666 (5.666)  Accm: 3.93 (3.93)  Acct: 6.08 (6.08)  time: 3.6873  data: 0.5484
[07-29 12:26:24] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   5/20]  [1365/2732]  eta: 1:24:09  tlr: 0.00015  tnm: 0.30  Lm: 6.344 (6.347)  Lt: 5.683 (5.686)  Accm: 3.85 (3.84)  Acct: 5.86 (5.95)  time: 3.7012  data: 0.5443
[07-29 13:08:25] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   5/20]  [2048/2732]  eta: 0:42:06  tlr: 0.00014  tnm: 0.32  Lm: 6.326 (6.329)  Lt: 5.666 (5.673)  Accm: 3.93 (3.91)  Acct: 5.94 (5.97)  time: 3.6791  data: 0.5457
[07-29 13:50:26] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   5/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00014  tnm: 0.31  Lm: 6.307 (6.313)  Lt: 5.648 (5.654)  Accm: 4.01 (3.94)  Acct: 6.02 (6.03)  time: 3.6896  data: 0.5448
[07-29 13:50:26] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   5/20]   Total time:      2:48:07   (3.693 s / it)
[07-29 13:52:10] (train.py                , line 236)=>  [*] [ep5]  (val 50000)  Lm: 6.2741, Lt: 5.6221, Acc m&t: 4.17 6.31,  Val cost: 104.16s
[07-29 13:52:10] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 13:52:30] (train.py                , line 253)=>      [ep5]  (training )  Lm: 6.274 (6.274), Lt: 5.622 (5.622),  Acc m&t: 4.17 6.31,  Remain: 1 day, 15:30:27,  Finish: 2025-07-30 21:20
[07-29 13:52:33] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   6/20]  [   0/2732]  eta: 2:48:07  tlr: 0.00014  tnm: 0.32  Lm: 6.294 (6.294)  Lt: 5.617 (5.617)  Accm: 4.11 (4.11)  Acct: 6.08 (6.08)  time: 3.6923  data: 0.5996
[07-29 14:34:31] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   6/20]  [ 682/2732]  eta: 2:06:07  tlr: 0.00014  tnm: 0.30  Lm: 6.258 (6.258)  Lt: 5.622 (5.622)  Accm: 4.38 (4.38)  Acct: 6.49 (6.49)  time: 3.7209  data: 0.5589
[07-29 15:16:33] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   6/20]  [1365/2732]  eta: 1:24:07  tlr: 0.00014  tnm: 0.31  Lm: 6.241 (6.253)  Lt: 5.617 (5.605)  Accm: 4.50 (4.42)  Acct: 6.89 (6.66)  time: 3.6968  data: 0.5644
[07-29 15:58:34] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   6/20]  [2048/2732]  eta: 0:42:05  tlr: 0.00014  tnm: 0.31  Lm: 6.268 (6.281)  Lt: 5.622 (5.624)  Accm: 4.31 (4.25)  Acct: 6.49 (6.52)  time: 3.6766  data: 0.5392
[07-29 16:40:29] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   6/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00013  tnm: 0.31  Lm: 6.265 (6.277)  Lt: 5.617 (5.620)  Accm: 4.11 (4.22)  Acct: 6.37 (6.49)  time: 3.6919  data: 0.5529
[07-29 16:40:29] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   6/20]   Total time:      2:47:59   (3.689 s / it)
[07-29 16:42:13] (train.py                , line 236)=>  [*] [ep6]  (val 50000)  Lm: 6.2689, Lt: 5.6113, Acc m&t: 4.19 6.38,  Val cost: 103.95s
[07-29 16:42:13] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 16:42:33] (train.py                , line 253)=>      [ep6]  (training )  Lm: 6.269 (6.269), Lt: 5.611 (5.611),  Acc m&t: 4.19 6.38,  Remain: 1 day, 12:46:10,  Finish: 2025-07-30 21:26
[07-29 16:42:36] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   7/20]  [   0/2732]  eta: 2:44:58  tlr: 0.00013  tnm: 0.30  Lm: 6.287 (6.287)  Lt: 5.650 (5.650)  Accm: 4.02 (4.02)  Acct: 5.92 (5.92)  time: 3.6232  data: 0.5580
[07-29 17:24:29] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   7/20]  [ 682/2732]  eta: 2:05:51  tlr: 0.00013  tnm: 0.32  Lm: 6.257 (6.257)  Lt: 5.598 (5.598)  Accm: 4.26 (4.26)  Acct: 6.41 (6.41)  time: 3.6654  data: 0.5415
[07-29 18:05:31] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   7/20]  [1365/2732]  eta: 1:23:02  tlr: 0.00013  tnm: 0.31  Lm: 6.228 (6.220)  Lt: 5.546 (5.559)  Accm: 4.50 (4.49)  Acct: 6.89 (6.62)  time: 3.7206  data: 0.5416
[07-29 18:47:11] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   7/20]  [2048/2732]  eta: 0:41:36  tlr: 0.00013  tnm: 0.31  Lm: 6.237 (6.227)  Lt: 5.559 (5.562)  Accm: 4.38 (4.43)  Acct: 6.85 (6.67)  time: 3.4874  data: 0.5708
[07-29 19:28:49] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   7/20]  [2731/2732]  eta: 0:00:03  tlr: 0.00012  tnm: 0.31  Lm: 6.228 (6.213)  Lt: 5.546 (5.555)  Accm: 4.50 (4.51)  Acct: 6.82 (6.69)  time: 3.6631  data: 0.5858
[07-29 19:28:49] (dgeVAR/VAR/utils/misc.py, line 336)=> [Ep]: [   7/20]   Total time:      2:46:16   (3.652 s / it)
[07-29 19:30:37] (train.py                , line 236)=>  [*] [ep7]  (val 50000)  Lm: 6.2334, Lt: 5.5805, Acc m&t: 4.35 6.58,  Val cost: 107.89s
[07-29 19:30:37] (train.py                , line 241)=> [saving ckpt] ...     [saving ckpt](*) finished!  @ /home/wangzefang/edgevar/EdgeVAR/VAR/traind_model/d16_0.2_0-20_200i/ar-ckpt-last.pth
[07-29 19:30:54] (train.py                , line 253)=>      [ep7]  (training )  Lm: 6.233 (6.233), Lt: 5.581 (5.581),  Acc m&t: 4.35 6.58,  Remain: 1 day, 9:39:18,  Finish: 2025-07-30 21:08
[07-29 19:30:57] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   8/20]  [   0/2732]  eta: 2:40:43  tlr: 0.00012  tnm: 0.32  Lm: 6.224 (6.224)  Lt: 5.561 (5.561)  Accm: 4.25 (4.25)  Acct: 6.68 (6.68)  time: 3.5299  data: 0.5688
[07-29 20:12:41] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   8/20]  [ 682/2732]  eta: 2:05:25  tlr: 0.00012  tnm: 0.31  Lm: 6.254 (6.254)  Lt: 5.586 (5.586)  Accm: 4.12 (4.12)  Acct: 6.48 (6.48)  time: 3.7002  data: 0.5478
[07-29 20:54:20] (dgeVAR/VAR/utils/misc.py, line 314)=> [Ep]: [   8/20]  [1365/2732]  eta: 1:23:30  tlr: 0.00012  tnm: 0.32  Lm: 6.224 (6.229)  Lt: 5.592 (5.588)  Accm: 4.25 (4.24)  Acct: 6.54 (6.50)  time: 3.7084  data: 0.5472
